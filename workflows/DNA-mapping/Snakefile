import os


### snakemake_workflows initialization ########################################
maindir = os.path.dirname(os.path.dirname(workflow.basedir))
sys.path.append(os.path.join(maindir, "shared"))

import common_functions as cf

# load tool paths
globals().update(cf.load_paths(os.path.join(maindir, "shared", "paths.yaml"),maindir,config["verbose"]))
# load config file
globals().update(cf.load_configfile(workflow.overwrite_configfile,config["verbose"]))
# load organism-specific data, i.e. genome indices, annotation, etc.
globals().update(cf.load_organism_data(genome,maindir,config["verbose"]))

# do workflow specific stuff now
include: os.path.join(workflow.basedir, "internals.snakefile")

if "allelic-mapping" in mode:
    # Updated global vars if mode = "allelic-mapping"
    if allele_mode == 'create_and_map':
        bowtie2_index_allelic = 'snp_genome/bowtie2_Nmasked/Genome.1.bt2'
        if len(strains) == 1:
            allele_hybrid = 'single'
            snp_file = "snp_genome/all_SNPs_" + strains[0] + "_" + genome + ".txt.gz "
        elif len(strains) == 2:
            allele_hybrid = 'dual'
            snp_file = "snp_genome/all_" + strains[1] + "_SNPs_" + strains[0] + "_reference.based_on_" + genome + ".txt"

        include: os.path.join(maindir, "shared", "rules", "masked_genomeIndex.snakefile")
    elif allele_mode == 'map_only':
        bowtie2_index_allelic = Nmasked_index
        snp_file = SNPfile
    ## mapping rules
    include: os.path.join(maindir, "shared", "rules", "Bowtie2_allelic.snakefile")
    ## SNPsplit
    include: os.path.join(maindir, "shared", "rules", "SNPsplit.snakefile")
    # deepTools QC
    include: os.path.join(maindir, "shared", "rules", "deepTools_qc_allelic.snakefile")
else:
    # Bowtie2 mapping, duplicate marking, BAM filtering and indexing
    include: os.path.join(maindir, "shared", "rules", "Bowtie2.snakefile")

### include modules of other snakefiles ########################################
################################################################################

# FASTQ: either downsample FASTQ files or create symlinks to input files
include: os.path.join(maindir, "shared", "rules", "FASTQ.snakefile")

# FastQC
if fastqc:
    include: os.path.join(maindir, "shared", "rules", "FastQC.snakefile")

# trimming
if trim:
    include: os.path.join(maindir, "shared", "rules", "TrimGalore.snakefile")

# BAM filtering
include: os.path.join(maindir, "shared", "rules", "bam_filtering.snakefile")

# Picard CollectAlignmentSummaryMetrics and CollectInsertSizeMetrics
include: os.path.join(maindir, "shared", "rules", "Picard_qc.snakefile")

#Sambamba Markdup
include: os.path.join(maindir, "shared", "rules", "sambamba.snakefile")
# deeptools cmds
include: os.path.join(maindir, "shared", "deeptools_cmds.snakefile")

# deepTools QC
include: os.path.join(maindir, "shared", "rules", "deepTools_qc.snakefile")

# Qualimap BAM QC
include: os.path.join(maindir, "shared", "rules", "Qualimap_bamqc.snakefile")

## MultiQC
include: os.path.join(maindir, "shared", "rules", "multiQC.snakefile")

### conditional/optional rules #################################################
################################################################################
def run_FastQC(fastqc):
    if fastqc:
        return( expand("FastQC/{sample}{read}_fastqc.html", sample = samples, read = reads) )
    else:
        return([])

def run_Trimming(trim, fastqc):
    if trim and fastqc:
        return( expand(fastq_dir+"/{sample}{read}.fastq.gz", sample = samples, read = reads) +
                expand("FastQC_trimmed/{sample}{read}_fastqc.html", sample = samples, read = reads) )
    elif trim:
        return( expand(fastq_dir+"/{sample}{read}.fastq.gz", sample = samples, read = reads) )
    else:
        return([])

def run_CollectInsertSizeMetrics(paired):
    if paired:
        return( expand("Picard_qc/InsertSizeMetrics/{sample}.insert_size_metrics.txt", sample = samples) )
    else:
        return([])

# def run_bamCoverage_filtered(dedup, properpairs, mapq):
#     if (dedup or properpairs or mapq > 0):
#         return( expand("bamCoverage/{sample}.filtered.seq_depth_norm.bw", sample = samples) )
#     else:
#         return([])

def run_computeGCBias(gcbias):
    if gcbias:
        file_list = expand("deepTools_qc/computeGCBias/{sample}.filtered.GCBias.png", sample = samples)
        if 'allelic-mapping' in mode:
            file_list.append(expand("deepTools_qc/computeGCBias/{sample}.{suffix}.GCBias.png",
                                    sample = samples, suffix = ['genome1', 'genome2']))
        return(file_list)
    else:
        return([])

def run_deepTools_qc():
    file_list = []
    if len(samples) <= 20:
        file_list.append( ["deepTools_qc/plotCoverage/read_coverage.png"] )
    if len(samples)>1 and len(samples)<=20:
        file_list.append( [
        "deepTools_qc/plotCorrelation/correlation.pearson.read_coverage.heatmap.png",
        "deepTools_qc/plotCorrelation/correlation.spearman.read_coverage.heatmap.png",
        "deepTools_qc/plotPCA/PCA.read_coverage.png",
        "deepTools_qc/estimateReadFiltering/EstimateReadFiltering.txt"] )
        if 'allelic-mapping' in mode:
            file_list.append( [
            "deepTools_qc/plotCorrelation/correlation.pearson.read_coverage_allelic.heatmap.png",
            "deepTools_qc/plotCorrelation/correlation.spearman.read_coverage_allelic.heatmap.png",
            "deepTools_qc/plotPCA/PCA.read_coverage_allelic.png" ] )

    return (file_list)

def run_Qualimap():
    file_list = []
    if qualimap:
        file_list += expand("Qualimap_qc/{sample}.filtered.bamqc_report.html", sample = samples)
        file_list += expand("Qualimap_qc/{sample}.filtered.bamqc_results.txt", sample = samples)
    return (file_list)
# allele specific
def make_nmasked_genome():
    if allele_mode == 'create_and_map':
        genome1 = "snp_genome/" + strains[0] + '_SNP_filtering_report.txt'
        file_list = [
                genome1,
                snp_file,
                bowtie2_index_allelic
                ]
        return(file_list)
    else:
        return([])

def run_allelesp_mapping():
    if "allelic-mapping" in mode:
        allele_suffix = ['allele_flagged', 'genome1', 'genome2', 'unassigned']
        file_list = [
        expand("allelic_bams/{sample}.{suffix}.sorted.bam", sample = samples,
                        suffix = allele_suffix),
        expand("allelic_bams/{sample}.{suffix}.sorted.bam.bai", sample = samples,
                        suffix = allele_suffix),
        expand("bamCoverage/allele_specific/{sample}.{suffix}.seq_depth_norm.bw", sample = samples,
                        suffix = ['genome1', 'genome2'])
        ]
        return(file_list)
    else:
        return([])

### execute before workflow starts #############################################
################################################################################
onstart:
    if "verbose" in config and config["verbose"]:
        print("--- Workflow parameters --------------------------------------------------------")
        print("samples:", samples)
        print("paired:", paired)
        print("read extension:", reads)
        print("fastq dir:", fastq_dir)
        print("maximum insert size (Bowtie2 -X):", insert_size_max)
        print("-" * 80, "\n")

        print("--- Environment ----------------------------------------------------------------")
        print("$TMPDIR: ",os.getenv('TMPDIR', ""))
        print("$HOSTNAME: ",os.getenv('HOSTNAME', ""))
        print("-" * 80, "\n")
#print(samples)

### main rule ##################################################################
################################################################################
rule all:
    input:
        expand("FASTQ/{sample}{read}.fastq.gz", sample = samples, read = reads),
        run_FastQC(fastqc),
        run_Trimming(trim, fastqc),
#       expand(mapping_prg+"/{sample}.bam", sample = samples),
        expand("Sambamba/{sample}.dup.converted.tsv", sample = samples),       
        expand(mapping_prg+"/{sample}.bam.bai", sample = samples),
        expand("filtered_bam/{sample}.filtered.bam", sample = samples),
        expand("Picard_qc/AlignmentSummaryMetrics/{sample}.alignment_summary_metrics.txt", sample = samples),
#       expand("Picard_qc/MarkDuplicates/{sample}.mark_duplicates_metrics.txt", sample = samples),
        run_CollectInsertSizeMetrics(paired),
        expand("bamCoverage/{sample}.seq_depth_norm.bw", sample = samples),
        expand("bamCoverage/{sample}.filtered.seq_depth_norm.bw", sample = samples),
        #run_bamCoverage_filtered(dedup, properpairs, mapq),
        run_computeGCBias(gcbias),
        run_deepTools_qc(),
        run_Qualimap(),
        make_nmasked_genome(),
        run_allelesp_mapping(),
        "multiQC/multiqc_report.html"


### execute after workflow finished ############################################
################################################################################
onsuccess:
    if "verbose" in config and config["verbose"]:
        print("\n--- DNA mapping workflow finished successfully! --------------------------------\n")
