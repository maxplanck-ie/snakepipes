#!/usr/bin/env python3

__version__ = "0.6"

__description__ = """
ChIP-seq workflow v{version} - MPI-IE workflow for ChIP-seq analysis

Usage example:
    ChIP-seq -d working-dir mm10 samples.yaml
""".format(version=__version__)

## Dependencies from DNA-mapping workflow
## OUTDIR/filtered_bam
##       /Picard_qc/AlignmentSummaryMetrics
##                 /MarkDuplicates
##                 /InsertSizeMetrics

import argparse
import os
import signal
import subprocess
import sys
import textwrap
import time
import shutil
import yaml
import inspect

#sys.path.append(os.path.abspath(os.path.dirname(inspect.getfile(inspect.currentframe()))) + "/shared/")
#sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(inspect.getfile(inspect.currentframe())))))+"/shared/")
sys.path.append(os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(os.path.realpath(inspect.getfile(inspect.currentframe()) )))))+"/shared/")

import common_functions as cf

def parse_args(defaults={"verbose":None,"configfile":None,"max_jobs":None,"snakemake_options":None,"tempdir":None,
                         "paired":None,"bw_binsize":None,"sample_info":"","window_size":None}):

    """
    Parse arguments from the command line.
    """

    parser = argparse.ArgumentParser(
        prog=sys.argv[0],
        formatter_class=argparse.RawDescriptionHelpFormatter,
        description=textwrap.dedent(__description__),
        add_help=False
    )

    #optional = parser._action_groups.pop() # Edited this line

    ## positional/required
    parser.add_argument("genome", metavar="GENOME", help="genome acronym of target organism (supported: 'dm3', 'dm6', 'hs37d5', 'mm9', 'mm10', 'SchizoSPombe_ASM294v2')")
    parser.add_argument("samples_config", metavar="SAMPLESCONFIG", help="configuration file (eg. 'example.chip_samples.yaml') with sample annotation")

    required = parser.add_argument_group('required arguments')
    required.add_argument("-d", "--working-dir",
                        dest="workingdir",
                        help="working directory is output directory and must contain DNA-mapping pipeline output files",
                        required=False,
                        default=".")

    general = parser.add_argument_group('general arguments')
    general.add_argument("-h", "--help",
                        action="help",
                        help="show this help message and exit")

    general.add_argument("-v", "--verbose",
                        dest="verbose",
                        action="store_true",
                        help="verbose output (default: '%(default)s')",
                        default=defaults["verbose"])

    general.add_argument("-c", "--configfile",
                        dest="configfile",
                        help="configuration file: config.yaml. In absence of a config file, the default options from the "
                        "workflows would be selected from /workflows/<workflow_name>/defaults.yaml (default: '%(default)s')",
                        default=defaults["configfile"])

    general.add_argument("-j", "--jobs",
                        dest="max_jobs",
                        metavar="INT",
                        help="maximum number of concurrently submitted Slurm jobs / cores if workflow is run locally (default: '%(default)s')",
                        type=int,
                        default=defaults["max_jobs"])

    general.add_argument("--local",
                        dest="local",
                        action="store_true",
                        default=False,
                        help="run workflow locally; default: jobs are submitted to Slurm queue (default: '%(default)s')")

    general.add_argument("--snakemake_options",
                        dest="snakemake_options",
                        metavar="STR",
                        type=str,
                        help="Snakemake options to be passed directly to snakemake, e.g. use --snakemake_options='--dryrun --rerun-incomplete --unlock --forceall'. (default: '%(default)s')", default=defaults["snakemake_options"])

    general.add_argument("--tempdir",
                        dest="tempdir",
                        type=str,
                        help="used prefix path for temporary directory created via mktemp. Created temp dir gets exported as $TMPDIR and is removed at the end of this wrapper! (default: '%(default)s')", default=defaults["tempdir"])

    ## optional
    optional = parser.add_argument_group('optional arguments')
    optional.add_argument("--single-end",
                        dest="paired",
                        action="store_false",
                        help="input data is single-end, not paired-end (default: '%(default)s')",
                        default=defaults["paired"])

    optional.add_argument("--bw-binsize",
                        dest="bw_binsize",
                        metavar="INT",
                        help="bin size of output files in bigWig format (default: '%(default)s')",
                        type=int,
                        default=defaults["bw_binsize"])

    optional.add_argument("--DB",
    					dest="sample_info",
    					help="Information on samples (If differential binding analysis required); see "
    						 "'snakemake_workflows/shared/tools/sampleInfo_DB.example.tsv' for example."
    						 " IMPORTANT: The first entry defines which group of samples are control. "
    						 " By this, the order of comparison and likewise the sign of values can be changed! (default: '%(default)s')",
    					default=defaults["sample_info"])

    optional.add_argument("--DB_windowSize",
    					dest="window_size",
    					help="Window size to counts reads in (If differential binding analysis required); "
    						 "Default size is suitable for most transcription factors and sharp histone marks. "
                             "Small window sizes (~20bp) should be used for very narrow transcription factor peaks, "
                             "while large window sizes (~500 bp) should be used for broad marks (eg. H3K27me3) "
                             "(default: '%(default)s')",
    					default=defaults["window_size"])

    return parser


def main():

    ## basic paths only used in wrapper
    #this_script_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))
    this_script_dir = os.path.dirname(os.path.realpath(__file__))
    main_dir_path = os.path.join(os.path.dirname(os.path.dirname(this_script_dir)))

    ## defaults
    defaults = cf.load_configfile(os.path.join(this_script_dir, "defaults.yaml"),False)

    ## get command line arguments
    parser = parse_args(defaults)
    args = parser.parse_args()

    ## we also add these paths to config, although we dont use them in the Snakefile
    args.this_script_dir = this_script_dir
    args.main_dir_path = main_dir_path

    ## checks for parameters necessary in wrapper
# 1. Dir path
    if os.path.exists(args.workingdir):
        args.workingdir = os.path.abspath(args.workingdir)
    else:
        print("\nError! Working-dir (-d) dir not found! ({})\n".format(args.workingdir))
        exit(1)
    args.outdir = args.workingdir
    args.cluster_logs_dir = os.path.join(args.outdir, "cluster_logs")
# 2. Config file
    if args.configfile and not os.path.exists(args.configfile):
        print("\nError! Provided configfile (-c) not found! ({})\n".format(args.configfile))
        exit(1)

    if os.path.exists(os.path.abspath(args.samples_config)):
        args.samples_config = os.path.abspath(args.samples_config)
    else:
        print("\nError! Sample config file not found! ({})\n".format(args.samples_config))
        exit(1)

# 3. Sample info file
    if args.sample_info:
        if os.path.exists(os.path.abspath(args.sample_info)):
            args.sample_info = os.path.abspath(args.sample_info)
        else:
            print("\nSample info file not found! (--DB {})\n".format(args.sample_info))
            exit(1)

    ## merge configuration dicts
    config = defaults   # 1) form defaults.yaml
    if args.configfile:
        user_config = cf.load_configfile(args.configfile,False)
        config = cf.merge_dicts(config, user_config) # 2) form user_config.yaml
    config_wrap = cf.config_diff(vars(args),defaults) # 3) from wrapper parameters
    config = cf.merge_dicts(config, config_wrap)
    #### Output directory + log directory
    subprocess.call("[ -d {cluster_logs_dir} ] || mkdir -p {cluster_logs_dir}".format(cluster_logs_dir=args.cluster_logs_dir), shell=True)

    ## save to configs.yaml in outdir
    cf.write_configfile(os.path.join(args.outdir,'ChIP-seq.config.yaml'),config)

    snakemake_module_load = "module load snakemake/3.12.0 slurm &&".split()
    snakemake_cmd = """
                    snakemake {snakemake_options} --latency-wait 300 --snakefile {snakefile} --jobs {max_jobs} --directory {workingdir} --configfile {configfile}
                    """.format( snakefile = os.path.join(this_script_dir, "Snakefile"),
                                max_jobs = args.max_jobs,
                                workingdir = args.workingdir,
                                snakemake_options=str(args.snakemake_options or ''),
                                configfile = os.path.join(args.outdir,'ChIP-seq.config.yaml'),
                              ).split()

    if args.verbose:
        snakemake_cmd.append("--printshellcmds")

    if not args.local:
        snakemake_cmd += ["--cluster 'SlurmEasy --threads {threads} --log", args.cluster_logs_dir, "--name {rule}.snakemake'"]

    snakemake_log = "2>&1 | tee -a {}/ChIP-seq.log".format(args.workingdir).split()

    ## create local temp dir and add this path to environment as $TMPDIR variable
    ## on SLURM: $TMPDIR is set, created and removed by SlurmEasy on cluster node
    temp_path = cf.make_temp_dir(args.tempdir, args.outdir)
    snakemake_exports = ("export TMPDIR="+temp_path+" && ").split()

    cmd = " ".join(snakemake_exports + snakemake_module_load + snakemake_cmd + snakemake_log)

    if args.verbose:
        print("\n", cmd, "\n")

    ## Write snakemake_cmd to log file
    with open(os.path.join(args.workingdir,"ChIP-seq.log"),"w") as f:
        f.write(" ".join(sys.argv)+"\n\n")
        f.write(cmd+"\n\n")

    ## Run snakemake
    p = subprocess.Popen(cmd, shell=True)
    if args.verbose:
        print("PID:", p.pid, "\n")
    try:
        p.wait()
    except:
        print("\nWARNING: Snakemake terminated!!!")
        if p.returncode != 0:
            if p.returncode:
                print("Returncode:", p.returncode)

            # kill snakemake and child processes
            subprocess.call(["pkill", "-SIGTERM", "-P", str(p.pid)])
            print("SIGTERM sent to PID:", p.pid)

            # # kill grid engine jobs
            # time.sleep(10)
            # job_ids = subprocess.check_output("""ls {cluster_logs_dir} | awk -F "." '{{print $NF}}' | sed 's/e\|o//' | sort -u""".format(cluster_logs_dir=cluster_logs_dir), shell=True).split()
            # for job_id in job_ids:
            #     subprocess.call( "qdel {} 2>&1 >/dev/null".format(str(job_id)), shell="bash" )

    ## remove temp dir
    if (temp_path != "" and os.path.exists(temp_path)):
        shutil.rmtree(temp_path, ignore_errors=True)
        if args.verbose:
            print("Temp directory removed ("+temp_path+")!\n")


if __name__ == "__main__":
    main()
