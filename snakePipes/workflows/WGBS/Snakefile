import os
import re
from operator import is_not
import glob
import io
import gzip
import snakePipes.common_functions as cf

### snakemake_workflows initialization ########################################
maindir = os.path.dirname(os.path.dirname(workflow.basedir))
workflow_tools=os.path.join(maindir, "shared", "tools")
workflow_rscripts=os.path.join(maindir, "shared", "rscripts")

# load conda ENVs (path is relative to "shared/rules" directory)
globals().update(cf.set_env_yamls())

# load config file
globals().update(cf.load_configfile(workflow.overwrite_configfile,config["verbose"]))
# load organism-specific data, i.e. genome indices, annotation, etc.
globals().update(cf.load_organism_data(genome,maindir,config["verbose"]))


refG=genome_fasta
crefG=bwameth_index

#this_script_dir = os.path.dirname(os.path.realpath(__file__))

### Sample init #############################################################

infiles = sorted(glob.glob(os.path.join(str(indir or ''), '*'+ext)))
samples = cf.get_sample_names(infiles,ext,reads)
paired = cf.is_paired(infiles,ext,reads)

if not samples:
    logger.error("  Error! NO samples found in dir "+str(indir or '')+"!!!")#\n \n\n
    exit(1)

if not paired:
    logger.error(" Error! Paired-end samples not detected. "
          "WGBS workflow currently works only with paired-end samples "+str(indir or '')+"!!!")#\n \n\n
    exit(1)

def get_Read_Group(INfiles):
    RG_dict={}
    for INfile in INfiles:
        with io.TextIOWrapper(gzip.open(INfile, 'r')) as f:
            file_content = f.readline().strip()
        read_root=re.sub('_R1.fastq.gz','',os.path.basename(INfile))
        PL=re.sub('@','',file_content).split(":")[0]
        PU=re.sub('@','',file_content).split(":")[2]
        RG='@RG"\\t"ID:1"\\t"SM:'+read_root+'"\\t"LB:'+read_root+'"\\t"PL:'+PL+'"\\t"PU:'+PU
        RG_dict[read_root]=RG
    return RG_dict

RG_dict=get_Read_Group(infiles)
del infiles

### conditional/optional rules #################################################
#some of those definitions are used to generate output strings for some of the rules
################################################################################

def run_cutadapt(trimReads):
    if trimReads=='user':
        return (expand("FASTQ_Cutadapt/{sample}{read}.fastq.gz", sample = samples, read = reads) + expand("FastQC_Cutadapt/{sample}{read}_fastqc.html", sample = samples, read = reads) )
    elif trimReads=='auto':
        return( expand("FastQC_In/{sample}.R12.ct.txt" ,sample = samples) + expand("FASTQ_Cutadapt/{sample}{read}.fastq.gz", sample = samples, read = reads) + expand("FastQC_Cutadapt/{sample}{read}_fastqc.html", sample = samples, read = reads) )
    elif trimReads is None:
        return([])

def convert_refG(convRef):
    if convRef:
        return (os.path.join('conv_ref',re.sub('.fa','.fa.bwameth.c2t',os.path.basename(refG))))
    else:
        return([])

def calc_doc(intList,wcard):
    if intList:
        int_dest=[re.sub('.bed','.mean.doc.sample_summary',os.path.basename(x)) for x in intList]
        int_dest[:0]=['mean.CG.doc.sample_summary']
        int_dest[:0]=['mean.genome.doc.sample_summary']
        if wcard:
            return ([os.path.join('QC_metrics',w) for w in expand('{{sample}}.{sfix}',sfix=int_dest)])
        else:
            return ([os.path.join('QC_metrics',w) for w in expand('{sample}.{sfix}',sample=samples,sfix=int_dest)])
    else:
        int_dest=['.mean.genome.doc.sample_summary','.mean.CG.doc.sample_summary']
        if wcard:
            return ([os.path.join('QC_metrics',w) for w in expand('{{sample}}.{sfix}',sfix=int_dest)])
        else:
            return ([os.path.join('QC_metrics',w) for w in expand('{sample}.{sfix}',sample=samples,sfix=int_dest)])


def run_CpG_stats(sampleInfo):
    if sampleInfo:
        return (['singleCpG_stats_limma/singleCpG.RData', 'singleCpG_stats_limma/limdat.LG.RData','singleCpG_stats_limma/metilene.IN.txt'])
    else:
        return ([])

def run_metilene_all(sampleInfo):
    if sampleInfo:
        return (['metilene_out/singleCpG.metilene.limma.bed','metilene_out/metilene.limma.annotated.txt'])
    else:
        return ([])


def run_int_aggStats(intList,sampleInfo):
    if intList and not sampleInfo:
        int_dest=[re.sub('.bed','.CpGlist.bed',os.path.basename(x)) for x in intList]
        return ([os.path.join("aux_files",re.sub('.fa',w,os.path.basename(refG))) for w in int_dest])
    if intList and sampleInfo:
            int_dest2=[re.sub('.bed','.aggCpG.RData',os.path.basename(x)) for x in intList]
            return ([os.path.join("aggregate_stats_limma",w) for w in int_dest2])
    else:
        return ([])



### include modules of other snakefiles ########################################
##some rules depend on the definitions above
################################################################################
# FASTQ: either downsample FASTQ files or create symlinks to input files
include: os.path.join(maindir, "shared", "rules", "FASTQ.snakefile")

# WGBS
include: os.path.join(maindir, "shared", "rules", "WGBS.snakefile")

# non-rule operations specific to the workflow
include: os.path.join(workflow.basedir, "internals.snakefile")


### execute before workflow starts #############################################
################################################################################
onstart:
    with open (os.path.join(outdir, 'pipeline.log'),"a") as lo:
        if "verbose" in config and config["verbose"]:
            print("--- Workflow parameters --------------------------------------------------------",file=lo)
            print("samples:"+ str(samples),file=lo)
            print("input dir:"+ indir,file=lo)
            print("-" * 80,file=lo)#, "\n"

            print("--- Environment ----------------------------------------------------------------",file=lo)
            print("$TMPDIR: "+os.getenv('TMPDIR', ""),file=lo)
            print("$HOSTNAME: "+os.getenv('HOSTNAME', ""),file=lo)
            print("-" * 80,file=lo)#, "\n"

### main rule ##################################################################
################################################################################
localrules: produce_report

rule all:
    input:
        expand("FASTQ/{sample}{read}.fastq.gz", sample = samples, read = reads),
        run_cutadapt(trimReads),
        expand("FASTQ_downsampled/{sample}{read}.fastq.gz", sample = samples, read = reads),
        convert_refG(convRef),
        expand("bams/{sample}.PCRrm.bam", sample = samples),
        expand("QC_metrics/{sample}.Mbias.txt",sample=samples),
        os.path.join("aux_files",re.sub('.fa','.poz.ran1M.sorted.bed',os.path.basename(refG))),
        calc_doc(intList,False),
        'QC_metrics/QC_report.pdf',
        expand("QC_metrics/{sample}.freq.txt",sample=samples),
        expand("QC_metrics/{sample}.GCbias.png",sample=samples),
        expand("methXT/{sample}_CpG.bedGraph",sample=samples),
        expand("methXT/{sample}.CpG.filt2.bed",sample=samples),
        run_CpG_stats(sampleInfo),
        run_metilene_all(sampleInfo),
        run_int_aggStats(intList,False),
        run_int_aggStats(intList,sampleInfo)

### execute after workflow finished ############################################
################################################################################
onsuccess:
    cf.cleanLogs(outdir)
    if "verbose" in config and config["verbose"]:
        with open (os.path.join(outdir, 'pipeline.log'),"a") as lo:
            print("--- WGBS workflow finished successfully! --------------------------------",file=lo)#\n \n
