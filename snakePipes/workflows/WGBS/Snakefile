import os
import re
from operator import is_not
import glob
import io
import gzip
import snakePipes.common_functions as cf

### snakemake_workflows initialization ########################################
maindir = os.path.dirname(os.path.dirname(workflow.basedir))
workflow_tools=os.path.join(maindir, "shared", "tools")
workflow_rscripts=os.path.join(maindir, "shared", "rscripts")

# load conda ENVs (path is relative to "shared/rules" directory)
globals().update(cf.set_env_yamls())

# load config file
globals().update(cf.load_configfile(workflow.overwrite_configfile,config["verbose"]))
if not convRef:
    # load organism-specific data, i.e. genome indices, annotation, etc.
    globals().update(cf.load_organism_data(genome,maindir,config["verbose"]))
    refG=genome_fasta
    crefG=bwameth_index
else:
    refG=genome
    crefG=os.path.join('aux_files',os.path.basename(refG))

###switch off read trimming rules if bam input provided ## this might be moved to a more useful location in the future
if trimReads=='None':
    trimReads=None

if fromBam:
    trimReads=None

##check if genes_bed is available
if not 'genes_bed' in globals():
    genes_bed='NA'

#this_script_dir = os.path.dirname(os.path.realpath(__file__))

### Sample init #############################################################
if not fromBam:
    infiles = sorted(glob.glob(os.path.join(str(indir or ''), '*'+ext)))
    samples = cf.get_sample_names(infiles,ext,reads)
    paired = cf.is_paired(infiles,ext,reads)

    if not samples:
        logger.error("  Error! NO samples found in dir "+str(indir or '')+"!!!")#\n \n\n
        exit(1)

    if not paired:
        logger.error(" Error! Paired-end samples not detected. "
              "WGBS workflow currently works only with paired-end samples "+str(indir or '')+"!!!")#\n \n\n
        exit(1)

    def get_Read_Group(INfiles):
        RG_dict={}
        for INfile in INfiles:
            with io.TextIOWrapper(gzip.open(INfile, 'r')) as f:
                file_content = f.readline().strip()
            read_root=re.sub('_R1.fastq.gz','',os.path.basename(INfile))
            PL=re.sub('@','',file_content).split(":")[0]
            PU=re.sub('@','',file_content).split(":")[2]
            RG='@RG"\\t"ID:1"\\t"SM:'+read_root+'"\\t"LB:'+read_root+'"\\t"PL:'+PL+'"\\t"PU:'+PU
            RG_dict[read_root]=RG
        return RG_dict

    RG_dict=get_Read_Group(infiles)
    del infiles

else:
    infiles = sorted(glob.glob(os.path.join(str(indir or ''), '*'+bam_ext)))
    samples = cf.get_sample_names_bam(infiles,bam_ext)
    ###add checks for existing read group
    del infiles



### conditional/optional rules #################################################
#some of those definitions are used to generate output strings for some of the rules
################################################################################

if not fromBam:

    def run_cutadapt(trimReads):
        if trimReads=='user':
            return (expand("FASTQ_Cutadapt/{sample}{read}.fastq.gz", sample = samples, read = reads) + expand("FastQC_Cutadapt/{sample}{read}_fastqc.html", sample = samples, read = reads) )
        elif trimReads=='auto':
            return( expand("FastQC_In/{sample}.R12.ct.txt" ,sample = samples) + expand("FASTQ_Cutadapt/{sample}{read}.fastq.gz", sample = samples, read = reads) + expand("FastQC_Cutadapt/{sample}{read}_fastqc.html", sample = samples, read = reads) )
        elif trimReads is None:
            return([])

def convert_refG(convRef):
    if convRef:
        return ([os.path.join('aux_files',re.sub('.fa','.fa.bwameth.c2t.sa',os.path.basename(refG))),os.path.join('aux_files',re.sub('.fa','.fa.bwameth.c2t.amb',os.path.basename(refG)))])
    else:
        return([])

def calc_doc(intList,wcard,skipDOC):
    if not skipDOC:
        if intList:
            int_dest=[re.sub('.bed','.mean.doc.sample_summary',os.path.basename(x)) for x in intList]
            int_dest[:0]=['mean.CG.doc.sample_summary']
            int_dest[:0]=['mean.genome.doc.sample_summary']
            if wcard:
                return ([os.path.join('QC_metrics',w) for w in expand('{{sample}}.{sfix}',sfix=int_dest)])
            else:
                return ([os.path.join('QC_metrics',w) for w in expand('{sample}.{sfix}',sample=samples,sfix=int_dest)])
        else:
            int_dest=['.mean.genome.doc.sample_summary','.mean.CG.doc.sample_summary']
            if wcard:
                return ([os.path.join('QC_metrics',w) for w in expand('{{sample}}.{sfix}',sfix=int_dest)])
            else:
                return ([os.path.join('QC_metrics',w) for w in expand('{sample}.{sfix}',sample=samples,sfix=int_dest)])
    else:
        return ([])

def get_outdir(folder_name):
    sample_name = re.sub('_sampleSheet.[a-z]{3}$','',os.path.basename(sampleInfo))
    return("{}_{}".format(folder_name, sample_name))


def run_CpG_stats(sampleInfo):
    if sampleInfo:

        return (['{}/singleCpG.RData'.format(get_outdir("singleCpG_stats_limma")), '{}/limdat.LG.RData'.format(get_outdir("singleCpG_stats_limma")),'{}/metilene.IN.txt'.format(get_outdir("singleCpG_stats_limma"))])
    else:
        return ([])

def run_metilene_all(sampleInfo):
    if sampleInfo:
        return (['{}/singleCpG.metilene.limma_unfiltered.bed'.format(get_outdir("metilene_out")),'{}/metilene.limma.annotated_unfiltered.txt'.format(get_outdir("metilene_out"))])
    else:
        return ([])


def run_int_aggStats(intList,sampleInfo):
    if intList and not sampleInfo:
        int_dest=[re.sub('.bed','.CpGlist.bed',os.path.basename(x)) for x in intList]
        return ([os.path.join("aux_files",re.sub('.fa',w,os.path.basename(refG))) for w in int_dest])
    if intList and sampleInfo:
            int_dest2=[re.sub('.bed','.aggCpG.RData',os.path.basename(x)) for x in intList]
            return ([os.path.join("{}".format(get_outdir("aggregate_stats_limma")),w) for w in int_dest2])
    else:
        return ([])

def run_deeptools(skipGCbias):
    if not skipGCbias:
        return (expand("QC_metrics/{sample}.freq.txt", sample = samples, read = reads) + expand("QC_metrics/{sample}.GCbias.png", sample = samples, read = reads))
    else:
        return ([])



### include modules of other snakefiles ########################################
##some rules depend on the definitions above
################################################################################
if not fromBam:
    # FASTQ: either downsample FASTQ files or create symlinks to input files
    include: os.path.join(maindir, "shared", "rules", "FASTQ.snakefile")

# WGBS
include: os.path.join(maindir, "shared", "rules", "WGBS.snakefile")

# non-rule operations specific to the workflow
include: os.path.join(workflow.basedir, "internals.snakefile")


### execute before workflow starts #############################################
################################################################################
onstart:
    with open (os.path.join(outdir, 'pipeline.log'),"a") as lo:
        if "verbose" in config and config["verbose"]:
            print("--- Workflow parameters --------------------------------------------------------",file=lo)
            print("samples:"+ str(samples),file=lo)
            print("input dir:"+ indir,file=lo)
            print("-" * 80,file=lo)#, "\n"

            print("--- Environment ----------------------------------------------------------------",file=lo)
            print("$TMPDIR: "+os.getenv('TMPDIR', ""),file=lo)
            print("$HOSTNAME: "+os.getenv('HOSTNAME', ""),file=lo)
            print("-" * 80,file=lo)#, "\n"

### main rule ##################################################################
################################################################################
if not fromBam:
    localrules:
        FASTQ,
        produce_report

    rule all:
        input:
            expand("FASTQ/{sample}{read}.fastq.gz", sample = samples, read = reads),
            expand("FASTQ_downsampled/{sample}{read}.fastq.gz", sample = samples, read = reads),
            convert_refG(convRef),
            expand("bams/{sample}.PCRrm.bam", sample = samples),
            expand("QC_metrics/{sample}.Mbias.txt",sample=samples),
            os.path.join("aux_files",re.sub('.fa','.poz.ran1M.sorted.bed',os.path.basename(refG))),
            calc_doc(intList,False,skipDOC),
            'QC_metrics/QC_report.html',
            run_deeptools(skipGCbias),
            expand("methXT/{sample}_CpG.bedGraph",sample=samples),
            expand("methXT/{sample}.CpG.filt2.bed",sample=samples),
            run_CpG_stats(sampleInfo),
            run_metilene_all(sampleInfo),
            run_int_aggStats(intList,False),
            run_int_aggStats(intList,sampleInfo)

else:
    localrules:
        link_bam,
        produce_report

    rule all:
        input:
            convert_refG(convRef),
            expand("bams/{sample}"+bam_ext, sample = samples),
            expand("QC_metrics/{sample}.Mbias.txt",sample=samples),
            os.path.join("aux_files",re.sub('.fa','.poz.ran1M.sorted.bed',os.path.basename(refG))),
            calc_doc(intList,False,skipDOC),
            'QC_metrics/QC_report.html',
            run_deeptools(skipGCbias),
            expand("methXT/{sample}_CpG.bedGraph",sample=samples),
            expand("methXT/{sample}.CpG.filt2.bed",sample=samples),
            run_CpG_stats(sampleInfo),
            run_metilene_all(sampleInfo),
            run_int_aggStats(intList,False),
            run_int_aggStats(intList,sampleInfo)

### execute after workflow finished ############################################
################################################################################
onsuccess:
    cf.cleanLogs(outdir)
    if "verbose" in config and config["verbose"]:
        with open (os.path.join(outdir, 'pipeline.log'),"a") as lo:
            print("--- WGBS workflow finished successfully! --------------------------------",file=lo)#\n \n
